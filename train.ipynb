{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SimTS** training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import forecasting as fcst\n",
    "\n",
    "from simts import SimTS\n",
    "from data_loader import *\n",
    "from utils import pkl_save, save_checkpoint_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set accurately the following parameters to train a SimTS model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"ETTh1\" # The dataset name.\n",
    "dir = os.getcwd() # The folder name used to save model outputs and evaluation metrics (current directory)\n",
    "loader = \"univar\" # The data loader used to load the data. This can be set to 'multivar' or 'univar'.\n",
    "batch_size = 8    # The batch size.\n",
    "K = 201           # K in the paper. Length of history segmentation.\n",
    "lr = 0.001        # Learning rate.\n",
    "repr_dims = 320   # Latent space dimensions.\n",
    "T = 402           # Training sample in the paper.\n",
    "iters = None      # Number of iterations.\n",
    "epochs = 5        # Number of epochs\n",
    "eval = True       # Whether to perform evaluation after training.\n",
    "save_every = 5    # Save the checkpoints every <save_every> epochs/iterations.\n",
    "seed = 1499       # Set random seed.\n",
    "\n",
    "kernel_list = [2 ** i for i in range(math.floor(math.log2(K)) + 1)] # List of kernel sizes used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store parameters inside a dictionary.\n",
    "args = dict(\n",
    "    dataset=dataset,\n",
    "    dir=dir,\n",
    "    loader=loader,\n",
    "    batch_size=batch_size,\n",
    "    K=K,\n",
    "    lr=lr,\n",
    "    repr_dims=repr_dims,\n",
    "    T=T,\n",
    "    kernel_list=kernel_list,\n",
    "    iters=iters,\n",
    "    epochs=epochs,\n",
    "    eval=eval,\n",
    "    save_every=save_every,\n",
    "    seed=seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset:\", dataset)\n",
    "print(\"Arguments:\", str(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds.\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set torch device.\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.cuda.current_device()\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration parameters.\n",
    "config = dict(\n",
    "    batch_size=batch_size,\n",
    "    lr=lr,\n",
    "    kernel_list=kernel_list,\n",
    "    output_dims=repr_dims,\n",
    "    K=K,\n",
    "    T=T,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set checkpoint callbacks.\n",
    "if save_every is not None:\n",
    "    unit = \"epoch\" if epochs is not None else \"iter\"\n",
    "    config[f\"after_{unit}_callback\"] = save_checkpoint_callback(save_every, unit)\n",
    "\n",
    "run_dir = dir + \"\\\\\" + dataset\n",
    "os.makedirs(run_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the chosen data with the appropriate data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading data..\", end=\"\")\n",
    "\n",
    "if loader == \"multivar\":\n",
    "    task_type = \"forecasting\"\n",
    "    data, train_slice, valid_slice, test_slice, scaler, pred_lens, n_covariate_cols = load_forecast_csv(dataset, univar=False)\n",
    "    train_data = data[:, train_slice]\n",
    "\n",
    "elif loader == \"univar\":\n",
    "    task_type = \"forecasting\"\n",
    "    data, train_slice, valid_slice, test_slice, scaler, pred_lens, n_covariate_cols = load_forecast_csv(dataset)\n",
    "    train_data = data[:, train_slice]\n",
    "    \n",
    "else:\n",
    "    raise ValueError(f\"Unknown loader {loader}\")\n",
    "\n",
    "print(\"Done.\", train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the SimTS model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "\n",
    "print(\"Train data size:\", train_data.shape)\n",
    "\n",
    "model = SimTS(\n",
    "    input_dims=train_data.shape[1],\n",
    "    **config\n",
    ")\n",
    "\n",
    "loss_log, best_net = model.fit(\n",
    "    train_data,\n",
    "    n_epochs=epochs,\n",
    "    n_iters=iters,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "t = time.time() - t\n",
    "print(f\"Training time: {datetime.timedelta(seconds=t)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the output results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval:\n",
    "    out, eval_res = fcst.eval_forecasting(model, data, train_slice, valid_slice, test_slice, scaler, pred_lens, n_covariate_cols)\n",
    "    \n",
    "    pkl_save(f\"{run_dir}/out.pkl\", out)\n",
    "    pkl_save(f\"{run_dir}/eval_res.pkl\", eval_res)\n",
    "    print(\"Evaluation result:\", eval_res)\n",
    "\n",
    "print(\"Finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
